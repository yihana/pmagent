# server/routers/pm_work.py
from typing import Dict, Any, Optional, List
from fastapi import APIRouter, Request, HTTPException, Query, UploadFile, File, Depends, Body
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session
import traceback
import shutil
from pathlib import Path
from datetime import datetime
import json
import csv
import logging
from server.db.database import get_db
from server.db import pm_crud, pm_models
from server.workflow.pm_graph import run_pipeline
from server.utils.doc_reader import read_texts, ingest_text, DocReadError
import shutil, re, time


router = APIRouter(prefix="/api/v1/pm", tags=["pm"])
logger = logging.getLogger(__name__)

# íŒŒì¼ ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •
UPLOAD_DIR = Path("data/inputs/RFP")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
try:
    from server.db.database import SessionLocal
    from server.db import pm_models
    _DB_AVAILABLE = True
except Exception:
    _DB_AVAILABLE = False
    SessionLocal = None
    pm_models = None

# âœ… DOCX í™•ì¥ì ì¶”ê°€
ALLOWED_EXTS = {".pdf", ".txt", ".md", ".docx"}

def _safe_filename(name: str) -> str:
    """ê°„ë‹¨ ìŠ¬ëŸ¬ê·¸í™”: ìœ„í—˜ë¬¸ì -> '_', ê³µë°± -> '_'"""
    name = name.strip().replace(" ", "_")
    # í•œê¸€/ì˜ë¬¸/ìˆ«ì/ì¼ë¶€ íŠ¹ìˆ˜ë¬¸ìë§Œ í—ˆìš©
    name = re.sub(r"[^0-9A-Za-zê°€-í£._()\-]", "_", name)
    # ë¹ˆ ì´ë¦„ ëŒ€ë¹„
    return name or f"upload_{int(time.time())}"

def _unique_path(base_dir: Path, filename: str) -> Path:
    """ì¤‘ë³µì‹œ _1, _2... ë¶™ì—¬ì„œ ìœ ë‹ˆí¬ ê²½ë¡œ ë°˜í™˜"""
    p = base_dir / filename
    if not p.exists():
        return p
    stem, suffix = Path(filename).stem, Path(filename).suffix
    i = 1
    while True:
        cand = base_dir / f"{stem}_{i}{suffix}"
        if not cand.exists():
            return cand
        i += 1


# ==== [ì¶”ê°€] ì¶œë ¥ í´ë” ìœ í‹¸ ====
def _scope_out_dir(project_id: str | int) -> Path:
    """
    Scope ì‚°ì¶œë¬¼ ê¸°ë³¸ í´ë”: <repo-root>/data/outputs/scope/<project_id>
    (í”„ë¡œì íŠ¸ë§ˆë‹¤ ê³ ì • ê²½ë¡œë¡œ ì €ì¥ë˜ë„ë¡ í†µì¼)
    """
    here = Path(__file__).resolve()
    root = here
    for p in here.parents:
        if (p / "data").exists():
            root = p
            break
    out = root / "data" / "outputs" / "scope" / str(project_id)
    out.mkdir(parents=True, exist_ok=True)
    return out


# ==== [ì¶”ê°€] ì‚°ì¶œë¬¼ ë³´ì • ìƒì„±ê¸° ====
def _write_requirements_json(project_id: str | int, requirements: list[dict], source: str = "") -> str:
    out_dir = _scope_out_dir(project_id)
    path = out_dir / "requirements.json"
    payload = {
        "project_id": str(project_id),
        "source": source,
        "generated_at": datetime.utcnow().isoformat(),
        "requirements": requirements or [],
    }
    path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    return str(path)


def _write_rtm_csv(project_id: str | int, requirements: list[dict], functions: list[dict] | None = None) -> str:
    """
    ê°„ë‹¨ round-robin RTM (ìš”êµ¬ì‚¬í•­ â†” ê¸°ëŠ¥) ìƒì„±.
    ê¸°ëŠ¥ì´ ì—†ìœ¼ë©´ ëª¨ë‘ F-000ìœ¼ë¡œ ë§¤í•‘.
    """
    out_dir = _scope_out_dir(project_id)
    path = out_dir / "rtm.csv"
    fieldnames = ["req_id", "function_id"]
    with path.open("w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        if not requirements:
            return str(path)
        fn_list = functions or [{"id": "F-000", "title": "Unassigned"}]
        for i, r in enumerate(requirements, start=1):
            req_id = r.get("req_id") or f"REQ-{i:03d}"
            fid = fn_list[(i - 1) % len(fn_list)]["id"]
            writer.writerow({"req_id": req_id, "function_id": fid})
    return str(path)


def _write_srs_md(project_id: str | int, requirements: list[dict], source: str = "") -> str:
    out_dir = _scope_out_dir(project_id)
    path = out_dir / "srs.md"
    lines = [
        f"# SRS (ìš”êµ¬ì‚¬í•­ ëª…ì„¸ì„œ)\n",
        f"- project_id: {project_id}",
        f"- source: {source}",
        f"- generated_at: {datetime.utcnow().isoformat()}",
        f"- requirements: {len(requirements or [])} ê°œ\n",
    ]
    for r in (requirements or []):
        rid = r.get("req_id", "")
        ttl = r.get("title", "")
        typ = r.get("type", "")
        pr  = r.get("priority", "")
        src = r.get("source_span", "")
        desc= r.get("description", "")
        lines += [
            f"## {rid} â€” {ttl}",
            f"- Type: {typ}",
            f"- Priority: {pr}",
            f"- Source: {src}\n",
            desc,
            ""
        ]
    path.write_text("\n".join(lines), encoding="utf-8")
    return str(path)


# ===============================
# ê³µìš© ëª¨ë¸
# ===============================

class AnalyzeRequest(BaseModel):
    project_id: int | str = Field(..., description="í”„ë¡œì íŠ¸ ID")
    doc_type: Optional[str] = Field(default="meeting")
    title: Optional[str] = Field(default=None)
    text: str = Field(..., description="ë¶„ì„ ì›ë¬¸")
    enable_rag: Optional[bool] = Field(default=True)


class AnalyzeResponse(BaseModel):
    status: str = "ok"
    data: Dict[str, Any] | list | None = None
    message: Optional[str] = None


class ReportResponse(BaseModel):
    status: str = "ok"
    data: Dict[str, Any] | list | None = None
    message: Optional[str] = None


# ===============================
# Scope ê´€ë ¨ ëª¨ë¸
# ===============================

class DocumentRef(BaseModel):
    path: str
    type: Optional[str] = "RFP"
    name: Optional[str] = None


class ScopeRequest(BaseModel):
    """
    Scope Agent Request
    
    RFP ë¬¸ì„œë¥¼ ì œê³µí•˜ëŠ” ë‘ ê°€ì§€ ë°©ë²•:
    1. text: ì§ì ‘ í…ìŠ¤íŠ¸ ì „ë‹¬ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
    2. documents: íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    project_id: Optional[int | str] = Field(default=None, description="í”„ë¡œì íŠ¸ ID")
    project_name: Optional[str] = Field(default=None, description="í”„ë¡œì íŠ¸ëª…")
    text: Optional[str] = Field(None, description="RFP í…ìŠ¤íŠ¸ (ì§ì ‘ ì „ë‹¬)")
    documents: Optional[List[DocumentRef]] = Field(default_factory=list, description="RFP íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸")
    methodology: Optional[str] = Field(default="waterfall", description="ë°©ë²•ë¡ : waterfall or agile")
    options: Optional[Dict[str, Any]] = Field(default_factory=dict, description="ì¶”ê°€ ì˜µì…˜")
    enable_rag: Optional[bool] = Field(default=True)


class ScopeResponse(BaseModel):
    """Scope Agent Response"""
    status: str
    message: Optional[str] = None
    project_id: str
    
    # íŒŒì¼ ê²½ë¡œ
    requirements_json: Optional[str] = None
    srs_path: Optional[str] = None
    rtm_csv: Optional[str] = None
    charter_path: Optional[str] = None
    business_plan_path: Optional[str] = None
    
    # íŒŒì‹±ëœ ë°ì´í„°
    requirements: List[Dict[str, Any]] = Field(default_factory=list)
    functions: List[Dict[str, Any]] = Field(default_factory=list)
    deliverables: List[Dict[str, Any]] = Field(default_factory=list)
    acceptance_criteria: List[Dict[str, Any]] = Field(default_factory=list)
    
    # RTM
    rtm_json: Optional[Dict[str, Any]] = None
    
    # PMP ì‚°ì¶œë¬¼ (Optionalë¡œ None í—ˆìš©)
    pmp_outputs: Optional[Dict[str, Optional[str]]] = Field(default_factory=dict)
    
    # í†µê³„
    stats: Optional[Dict[str, int]] = None


# ===============================
# Schedule ê´€ë ¨ ëª¨ë¸
# ===============================

class CalendarModel(BaseModel):
    start_date: Optional[str] = None
    work_week: Optional[List[int]] = Field(default=[1, 2, 3, 4, 5])
    holidays: Optional[List[str]] = Field(default_factory=list)


class ResourceModel(BaseModel):
    role: str
    capacity_pct: Optional[int] = 100


class ScheduleRequest(BaseModel):
    """
    Schedule Agent Request
    
    WBS ìƒì„± ë°©ë²•:
    1. requirements: Scope Agent ê²°ê³¼ ì „ë‹¬ â†’ WBS ìë™ ìƒì„±
    2. wbs_json: ê¸°ì¡´ WBS JSON ì „ë‹¬ â†’ ì¼ì •ë§Œ ê³„ì‚°
    """
    project_id: Optional[int | str] = Field(default=None, description="í”„ë¡œì íŠ¸ ID")
    
    # WBS ìƒì„±ìš©
    requirements: Optional[List[Dict[str, Any]]] = Field(None, description="ìš”êµ¬ì‚¬í•­ ë¦¬ìŠ¤íŠ¸ (WBS ìë™ ìƒì„±)")
    
    # ê¸°ì¡´ WBS ì‚¬ìš©
    wbs_json: Optional[str] = Field(None, description="WBS JSON (íŒŒì¼ ê²½ë¡œ ë˜ëŠ” JSON ë¬¸ìì—´)")
    
    # ë°©ë²•ë¡  & ì¼ì • ì„¤ì •
    methodology: Optional[str] = Field(default="waterfall", description="ë°©ë²•ë¡ : waterfall or agile")
    calendar: Optional[CalendarModel] = Field(default_factory=CalendarModel, description="ìº˜ë¦°ë” ì„¤ì •")
    sprint_length_weeks: Optional[int] = Field(default=2, description="Agile: Sprint ê¸¸ì´ (ì£¼)")
    
    # Sprint ë°±ë¡œê·¸ (Agile ì „ìš©)
    sprint_backlogs: Optional[List[Dict[str, Any]]] = Field(None, description="Sprint ë°±ë¡œê·¸")
    
    # Resource pool
    resource_pool: Optional[List[ResourceModel]] = Field(default_factory=list)
    
    # Change Request
    change_requests: Optional[List[Dict[str, Any]]] = Field(None, description="ë³€ê²½ ìš”ì²­ ë¦¬ìŠ¤íŠ¸")
    
    # ì¶”ê°€ ì˜µì…˜
    estimation_mode: Optional[str] = Field(default="heuristic", description="ì¶”ì • ëª¨ë“œ: llm or heuristic")


class ScheduleResponse(BaseModel):
    """Schedule Agent Response"""
    status: str
    message: Optional[str] = None
    project_id: str
    methodology: str
    
    # íŒŒì¼ ê²½ë¡œ
    wbs_json_path: Optional[str] = None
    plan_csv: Optional[str] = None
    gantt_json: Optional[str] = None
    timeline_path: Optional[str] = None
    burndown_json: Optional[str] = None
    
    # íŒŒì‹±ëœ ë°ì´í„° (list íƒ€ì…)
    critical_path: List[Dict[str, Any]] = Field(default_factory=list, description="Critical path tasks")
    timeline: List[Dict[str, Any]] = Field(default_factory=list, description="Timeline tasks")
    
    # PMP ì‚°ì¶œë¬¼
    pmp_outputs: Optional[Dict[str, str]] = None
    
    # ì¶”ê°€ ë°ì´í„°
    data: Optional[Dict[str, Any]] = None
    
    # Change Request ê²°ê³¼
    change_requests: Optional[Dict[str, Any]] = None


# ===============================
# Workflow ëª¨ë¸
# ===============================

class WorkflowRequest(BaseModel):
    """
    í†µí•© Workflow Request (Scope â†’ Schedule)
    """
    project_id: str = Field(..., description="í”„ë¡œì íŠ¸ ID")
    text: Optional[str] = Field(None, description="RFP í…ìŠ¤íŠ¸")
    documents: Optional[List[DocumentRef]] = Field(default_factory=list, description="RFP íŒŒì¼ ê²½ë¡œ")
    methodology: Optional[str] = Field(default="waterfall", description="ë°©ë²•ë¡ : waterfall or agile")
    calendar: Optional[CalendarModel] = Field(default_factory=CalendarModel, description="ìº˜ë¦°ë” ì„¤ì •")
    sprint_length_weeks: Optional[int] = Field(default=2, description="Agile: Sprint ê¸¸ì´ (ì£¼)")


class WorkflowResponse(BaseModel):
    """í†µí•© Workflow Response"""
    status: str
    message: Optional[str] = None
    project_id: str
    scope: ScopeResponse
    schedule: ScheduleResponse
    summary: Optional[Dict[str, Any]] = None

# ===============================
# ê¸°ì¡´: ê·¸ë˜í”„ ë¶„ì„ / ë¦¬í¬íŠ¸
# ===============================

@router.post("/graph/analyze", response_model=AnalyzeResponse)
async def graph_analyze(payload: AnalyzeRequest):
    """
    ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ìœ ì§€: ê·¸ë˜í”„ ê¸°ë°˜ ë¶„ì„ í˜¸ì¶œ
    íšŒì˜ë¡ ë¶„ì„ â†’ Action Items ì¶”ì¶œ ë° DB ì €ì¥
    """
    try:
        result = await run_pipeline(kind="analyze", payload=payload.model_dump())
        
        # ì €ì¥ ì§í›„ ë°”ë¡œ ì•¡ì…˜ ì•„ì´í…œ ëª©ë¡ ì¡°íšŒ
        project_id = result.get("project_id")
        saved_count = result.get("saved_action_items", 0)
        
        # DBì—ì„œ ë°©ê¸ˆ ì €ì¥ëœ ì•¡ì…˜ ì•„ì´í…œ ì¡°íšŒ
        action_items_list = []
        if saved_count > 0 and project_id:
            try:
                from server.db.database import SessionLocal
                
                db = SessionLocal()
                try:
                    # ë°©ê¸ˆ ì €ì¥ëœ ë¬¸ì„œì˜ ì•¡ì…˜ ì•„ì´í…œ ì¡°íšŒ
                    document_id = result.get("document_id")
                    items = db.query(pm_models.PM_ActionItem)\
                        .filter(pm_models.PM_ActionItem.document_id == document_id)\
                        .all()
                    
                    action_items_list = [
                        {
                            "id": item.id,
                            "task": item.task,
                            "assignee": item.assignee,
                            "due_date": str(item.due_date) if item.due_date else None,
                            "priority": item.priority,
                            "status": item.status,
                            "module": item.module,
                            "phase": item.phase
                        }
                        for item in items
                    ]
                finally:
                    db.close()
            except Exception as e:
                logger.warning(f"Failed to fetch action items: {e}")
        
        # ì‘ë‹µ êµ¬ì¡° ê°œì„ 
        response_data = {
            "ok": result.get("ok", True),
            "project_id": project_id,
            "document_id": result.get("document_id"),
            "meeting_id": result.get("meeting_id"),
            "saved_action_items": saved_count,
            "action_items": action_items_list,  # ì‹¤ì œ ëª©ë¡ í¬í•¨
            "action_items_summary": result.get("action_items"),  # ê¸°ì¡´ ìš”ì•½ ì •ë³´
            "title": payload.title or "Untitled",
            "doc_type": payload.doc_type or "meeting"
        }
        
        return AnalyzeResponse(
            status="ok", 
            data=response_data,
            message=f"ë¶„ì„ ì™„ë£Œ: {saved_count}ê°œ ì•¡ì…˜ ì•„ì´í…œ ì €ì¥ë¨"
        )
    except Exception as e:
        logger.exception(f"[Analyze] Error: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/graph/report", response_model=ReportResponse)
async def graph_report(project_id: int = Query(..., description="í”„ë¡œì íŠ¸ ID")):
    """
    ê¸°ì¡´ ë¦¬í¬íŠ¸ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        result = await run_pipeline(kind="report", payload={"project_id": project_id})
        return ReportResponse(status="ok", data=result)
    except Exception as e:
        logger.exception(f"[Report] Error: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


# server/routers/pm_work.py
@router.post("/upload/rfp")
async def upload_rfp(file: UploadFile = File(...)):
    """RFP íŒŒì¼ ì—…ë¡œë“œ (PDF/TXT/MD/DOCX)"""
    MAX_FILE_SIZE = 200 * 1024 * 1024
    
    try:
        if not file.filename:
            raise ValueError("íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤")
        
        orig = file.filename
        ext = Path(orig).suffix.lower()
        
        print(f"ğŸ”µ [UPLOAD] íŒŒì¼: {orig}, í™•ì¥ì: {ext}, ALLOWED_EXTS={ALLOWED_EXTS}")
        logger.info(f"[UPLOAD] ìš”ì²­: {orig} ({ext})")

        if ext not in ALLOWED_EXTS:
            print(f"ğŸ”´ [UPLOAD] í™•ì¥ì ê±°ë¶€! {ext} not in {ALLOWED_EXTS}")
            allowed = ', '.join(sorted(ALLOWED_EXTS))
            raise HTTPException(status_code=400, detail=f"í™•ì¥ì ì˜¤ë¥˜: {allowed}")

        safe = _safe_filename(orig)
        if Path(safe).suffix.lower() != ext:
            safe = f"{Path(safe).stem}{ext}"
        file_path = _unique_path(UPLOAD_DIR, safe)
        
        print(f"ğŸ”µ [UPLOAD] ì €ì¥ê²½ë¡œ: {file_path}")

        content_length = file.size
        if content_length and content_length > MAX_FILE_SIZE:
            print(f"ğŸ”´ [UPLOAD] íŒŒì¼í¬ê¸° ì´ˆê³¼: {content_length / 1024 / 1024:.1f}MB")
            raise HTTPException(status_code=413, detail="íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤")

        try:
            import shutil as shutil_module
            stat = shutil_module.disk_usage(UPLOAD_DIR)
            free_space = stat.free
            if free_space < (content_length or 0) + (50 * 1024 * 1024):
                print(f"ğŸ”´ [UPLOAD] ë””ìŠ¤í¬ ë¶€ì¡±: {free_space / 1024 / 1024:.0f}MB")
                raise HTTPException(status_code=507, detail="ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±")
            print(f"ğŸ”µ [UPLOAD] ë””ìŠ¤í¬OK: {free_space / 1024 / 1024:.0f}MB")
        except Exception as e:
            logger.warning(f"[UPLOAD] ë””ìŠ¤í¬ ì²´í¬ ì‹¤íŒ¨: {e}")

        if not UPLOAD_DIR.exists():
            UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ”µ [UPLOAD] ë””ë ‰í† ë¦¬ ìƒì„±: {UPLOAD_DIR}")

        try:
            print(f"ğŸ”µ [UPLOAD] ì €ì¥ ì‹œì‘...")
            with file_path.open("wb") as buffer:
                chunk_size = 1024 * 1024
                total_written = 0
                while True:
                    chunk = await file.read(chunk_size)
                    if not chunk:
                        break
                    buffer.write(chunk)
                    total_written += len(chunk)
                    print(f"ğŸ”µ [UPLOAD] ì§„í–‰: {total_written / 1024:.1f}KB")
                    
                    if total_written > MAX_FILE_SIZE:
                        file_path.unlink()
                        raise HTTPException(status_code=413, detail="íŒŒì¼ í¬ê¸° ì´ˆê³¼")
            
            print(f"âœ… [UPLOAD] ì €ì¥ì™„ë£Œ: {total_written} bytes")
            logger.info(f"[UPLOAD] ì €ì¥ì™„ë£Œ: {total_written} bytes")
        
        except IOError as e:
            try:
                file_path.unlink()
            except:
                pass
            print(f"ğŸ”´ [UPLOAD] IOì—ëŸ¬: {e}")
            raise HTTPException(status_code=507, detail=f"ì €ì¥ì‹¤íŒ¨: {str(e)}")
        except Exception as e:
            try:
                file_path.unlink()
            except:
                pass
            raise

        if not file_path.exists():
            print(f"ğŸ”´ [UPLOAD] íŒŒì¼ ë¯¸í™•ì¸: {file_path}")
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì—†ìŒ")
        
        size = file_path.stat().st_size
        if size == 0:
            file_path.unlink()
            print(f"ğŸ”´ [UPLOAD] ë¹ˆ íŒŒì¼")
            raise HTTPException(status_code=400, detail="ë¹ˆ íŒŒì¼")
        
        print(f"âœ… [UPLOAD] ê²€ì¦ì™„ë£Œ: {size} bytes")
        relative_path = f"data/inputs/RFP/{file_path.name}"

        response = {
            "status": "ok",
            "filename": file_path.name,
            "path": relative_path,
            "abs_path": str(file_path.resolve()),
            "size": size,
            "ext": ext,
            "message": f"íŒŒì¼ ì—…ë¡œë“œ: {relative_path}"
        }
        
        print(f"âœ… [UPLOAD] ì„±ê³µë°˜í™˜: {relative_path}")
        logger.info(f"[UPLOAD] ì„±ê³µ: {relative_path}")
        return response

    except HTTPException:
        raise
    except ValueError as e:
        print(f"ğŸ”´ [UPLOAD] ValueError: {e}")
        logger.error(f"[UPLOAD] ìœ íš¨ì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        print(f"ğŸ”´ [UPLOAD] ì˜ˆìƒ ì˜¤ë¥˜: {type(e).__name__}: {e}")
        logger.exception(f"[UPLOAD] ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


@router.post("/scope/analyze", response_model=ScopeResponse)
async def scope_analyze(request: ScopeRequest):
    """Scope ë¶„ì„"""
    project_id = request.project_id or request.project_name or "default"
    methodology = request.methodology or "waterfall"
    
    print(f"ğŸ”µ [SCOPE] ìš”ì²­: project_id={project_id}, methodology={methodology}")
    logger.info(f"[SCOPE] ìš”ì²­: {project_id}")

    payload: dict = {"project_id": project_id, "methodology": methodology}
    source_label = "inline-text"

    try:
        if request.text and str(request.text).strip():
            print(f"ğŸ”µ [SCOPE] ëª¨ë“œ: ì§ì ‘ì…ë ¥, ê¸¸ì´={len(request.text)}")
            payload["text"] = str(request.text).strip()

        elif request.documents:
            print(f"ğŸ”µ [SCOPE] ëª¨ë“œ: íŒŒì¼ê²½ë¡œ, ê°œìˆ˜={len(request.documents)}")
            paths: list[str] = []
            for d in request.documents:
                path_val = getattr(d, "path", None) or (d.get("path") if isinstance(d, dict) else None)
                if path_val:
                    paths.append(path_val)
            
            if not paths:
                print(f"ğŸ”´ [SCOPE] ê²½ë¡œ ì—†ìŒ")
                raise HTTPException(status_code=400, detail="ê²½ë¡œ í•„ìš”")

            print(f"ğŸ”µ [SCOPE] íŒŒì¼ì½ê¸°: {paths}")
            merged_text, metas = read_texts(
                paths,
                header=True,
                search_roots=[Path("data/inputs/RFP"), Path("data")]
            )
            if not merged_text.strip():
                print(f"ğŸ”´ [SCOPE] í…ìŠ¤íŠ¸ ì—†ìŒ")
                raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ ì—†ìŒ")

            print(f"ğŸ”µ [SCOPE] í…ìŠ¤íŠ¸ê¸¸ì´: {len(merged_text)}")
            payload["text"] = merged_text
            source_label = ", ".join([Path(m.get("resolved_path") or m["path"]).name for m in metas])

        else:
            print(f"ğŸ”´ [SCOPE] ì…ë ¥ ì—†ìŒ")
            raise HTTPException(status_code=400, detail="ì…ë ¥ í•„ìš”")

    except DocReadError as e:
        print(f"ğŸ”´ [SCOPE] íŒŒì¼ì½ê¸°ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))

    if request.options:
        payload["options"] = dict(request.options)

    print(f"ğŸ”µ [SCOPE] íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ ì‹œì‘...")
    result = await run_pipeline(kind="scope", payload=payload)
    
    print(f"ğŸ”µ [SCOPE] íŒŒì´í”„ë¼ì¸ ê²°ê³¼: type={type(result)}")
    if result is None:
        print(f"ğŸ”´ [SCOPE] íŒŒì´í”„ë¼ì¸ì´ None ë°˜í™˜!")
        logger.error("[SCOPE] Pipeline None")
        raise HTTPException(status_code=500, detail="Pipeline None")

    if not isinstance(result, dict):
        print(f"ğŸ”´ [SCOPE] íŒŒì´í”„ë¼ì¸ì´ dict ì•„ë‹˜: {type(result)}")
        raise HTTPException(status_code=500, detail=f"Pipeline {type(result)}")

    status = result.get("status", "ok")
    if status not in (None, "ok"):
        print(f"ğŸ”´ [SCOPE] íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: status={status}")
        raise HTTPException(status_code=400, detail=result.get("message", "ì‹¤íŒ¨"))

    requirements = result.get("requirements") or []
    functions = result.get("functions") or []
    deliverables = result.get("deliverables") or []
    acceptance = result.get("acceptance_criteria") or []
    stats = result.get("stats")
    
    print(f"âœ… [SCOPE] íŒŒì‹±ì™„ë£Œ: {len(requirements)}ê°œ ìš”êµ¬ì‚¬í•­, {len(functions)}ê°œ ê¸°ëŠ¥")

    req_json_path = result.get("requirements_json")
    rtm_csv_path = result.get("rtm_csv")
    srs_path = result.get("srs_path")

    if not req_json_path:
        req_json_path = _write_requirements_json(project_id, requirements, source_label)
        print(f"ğŸ”µ [SCOPE] requirements.json ìƒì„±: {req_json_path}")

    if not rtm_csv_path:
        rtm_csv_path = _write_rtm_csv(project_id, requirements, functions)
        print(f"ğŸ”µ [SCOPE] rtm.csv ìƒì„±: {rtm_csv_path}")

    if not srs_path:
        srs_path = _write_srs_md(project_id, requirements, source_label)
        print(f"ğŸ”µ [SCOPE] srs.md ìƒì„±: {srs_path}")

    if _DB_AVAILABLE and requirements:
        db = SessionLocal()
        saved = 0
        try:
            for i, r in enumerate(requirements, start=1):
                req_key = r.get("req_id") or f"REQ-{i:03d}"
                try:
                    obj = pm_models.PM_Requirement(
                        project_id=project_id,
                        req_key=req_key,
                        title=r.get("title") or "",
                        description=r.get("description") or "",
                        priority=r.get("priority") or "Medium",
                        req_type=r.get("type") or "General",
                        source_span=r.get("source_span") or source_label,
                        created_at=datetime.utcnow()
                    )
                    db.add(obj)
                    saved += 1
                except Exception as e:
                    logger.debug(f"[SCOPE] ìŠ¤í‚µ: {req_key}")
                    continue
            db.commit()
            print(f"âœ… [SCOPE] DBì €ì¥: {saved}ê°œ")
        except Exception as e:
            db.rollback()
            print(f"ğŸ”´ [SCOPE] DBì˜¤ë¥˜: {e}")
        finally:
            db.close()

    response = ScopeResponse(
        status="ok",
        message=result.get("message"),
        project_id=str(project_id),
        requirements_json=req_json_path,
        srs_path=srs_path,
        rtm_csv=rtm_csv_path,
        charter_path=result.get("charter_path"),
        business_plan_path=result.get("business_plan_path"),
        requirements=requirements,
        functions=functions,
        deliverables=deliverables,
        acceptance_criteria=acceptance,
        rtm_json=result.get("rtm_json"),
        pmp_outputs=result.get("pmp_outputs"),
        stats=stats,
    )
    
    print(f"âœ… [SCOPE] ì‘ë‹µì™„ë£Œ: {project_id}")
    return response


@router.get("/scope/summary")
async def scope_summary(project_id: str = Query(..., description="í”„ë¡œì íŠ¸ ID")):
    """
    Scope ìš”ì•½ ì¡°íšŒ (project_id ê¸°ì¤€)
    """
    try:
        result = await run_pipeline(kind="scope_summary", payload={"project_id": project_id})
        return {"status": "ok", "data": result}
    except Exception as e:
        logger.exception(f"[Scope Summary] Error: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


# ë””ë²„ê·¸
@router.post("/scope/seed_golden")
async def seed_golden(project_id: int = Body(...), data: dict = Body(...)):
    # golden JSONì„ ë°›ì•„ pm_requirementsì— upsert
    db = next(get_db())
    try:
        for r in data.get("requirements", []):
            obj = db.query(pm_models.PM_Requirement)\
                    .filter(pm_models.PM_Requirement.project_id == project_id,
                            pm_models.PM_Requirement.req_id == r["req_id"])\
                    .one_or_none()
            if obj is None:
                obj = pm_models.PM_Requirement(project_id=project_id, req_id=r["req_id"])
                db.add(obj)
            obj.title = r.get("title")
            obj.type = r.get("type")
            obj.priority = r.get("priority")
            obj.description = r.get("description")
            obj.source_doc = r.get("source_span")
        db.commit()
        return {"ok": True, "saved": len(data.get("requirements", []))}
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()


# ===============================
# ì‹ ê·œ: Schedule Agent (ì¼ì •ê´€ë¦¬)
# ===============================

@router.post("/schedule/analyze", response_model=ScheduleResponse)
async def schedule_analyze(request: ScheduleRequest):
    """
    Schedule Agent: Requirements â†’ WBS â†’ ì¼ì • ê³„íš
    
    Examples:
        # 1. Requirementsë¡œ WBS ìƒì„±
        {
          "project_id": "P001",
          "requirements": [...],
          "methodology": "agile",
          "calendar": {"start_date": "2025-02-01"}
        }
        
        # 2. ê¸°ì¡´ WBS ì‚¬ìš©
        {
          "project_id": "P001",
          "wbs_json": "/path/to/wbs.json",
          "methodology": "waterfall"
        }
        
        # 3. Change Request
        {
          "project_id": "P001",
          "wbs_json": "/path/to/wbs.json",
          "change_requests": [
            {"op": "update_duration", "task_id": "WBS-1.1", "new_duration": 10}
          ]
        }
    """
    try:
        # Payload êµ¬ì„±
        payload = {
            "project_id": request.project_id or "default",
            "methodology": request.methodology or "waterfall",
            "calendar": request.calendar.model_dump() if request.calendar else {},
            "sprint_length_weeks": request.sprint_length_weeks or 2,
            "estimation_mode": request.estimation_mode or "heuristic",
        }
        
        # Requirements ë˜ëŠ” WBS JSON
        if request.requirements:
            payload["requirements"] = request.requirements
        elif request.wbs_json:
            payload["wbs_json"] = request.wbs_json
        else:
            raise ValueError("Either 'requirements' or 'wbs_json' must be provided")
        
        # Sprint backlogs (Agile)
        if request.sprint_backlogs:
            payload["sprint_backlogs"] = request.sprint_backlogs
        
        # Change requests
        if request.change_requests:
            payload["change_requests"] = request.change_requests
        
        # Schedule Agent ì‹¤í–‰
        result = await run_pipeline("schedule", payload)
        
        if result.get("status") != "ok":
            raise ValueError(result.get("message", "Schedule analysis failed"))
        
        # Critical path íŒŒì‹±
        critical_path_data = []
        if result.get("_parsed_critical_path"):
            critical_path_data = result["_parsed_critical_path"]
        elif result.get("critical_path") and isinstance(result["critical_path"], str):
            try:
                cp_path = Path(result["critical_path"])
                if cp_path.exists():
                    cp_content = json.loads(cp_path.read_text(encoding="utf-8"))
                    if isinstance(cp_content, dict) and "critical_path" in cp_content:
                        critical_path_data = cp_content["critical_path"]
                    elif isinstance(cp_content, list):
                        critical_path_data = cp_content
            except Exception as e:
                logger.warning(f"Failed to parse critical_path: {e}")
        
        # Timeline íŒŒì‹±
        timeline_data = []
        if result.get("timeline") and isinstance(result["timeline"], str):
            try:
                timeline_path = Path(result["timeline"])
                if timeline_path.exists():
                    timeline_content = json.loads(timeline_path.read_text(encoding="utf-8"))
                    if isinstance(timeline_content, dict) and "tasks" in timeline_content:
                        timeline_data = timeline_content["tasks"]
                    elif isinstance(timeline_content, list):
                        timeline_data = timeline_content
            except Exception as e:
                logger.warning(f"Failed to parse timeline: {e}")
        
        return ScheduleResponse(
            status="ok",
            message=result.get("message", "Schedule generated successfully"),
            project_id=str(payload["project_id"]),
            methodology=result.get("methodology", payload["methodology"]),
            
            # íŒŒì¼ ê²½ë¡œ
            wbs_json_path=result.get("wbs_json_path"),
            plan_csv=result.get("plan_csv"),
            gantt_json=result.get("gantt_json"),
            timeline_path=result.get("timeline"),
            burndown_json=result.get("burndown_json"),
            
            # íŒŒì‹±ëœ ë°ì´í„°
            critical_path=critical_path_data,
            timeline=timeline_data,
            
            # PMP ì‚°ì¶œë¬¼
            pmp_outputs=result.get("pmp_outputs", {}),
            
            # ë°ì´í„°
            data=result.get("data"),
            
            # Change Request ê²°ê³¼
            change_requests=result.get("change_requests")
        )
        
    except ValueError as e:
        logger.error(f"[Schedule Agent] Validation Error: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.exception(f"[Schedule Agent] Error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Schedule analysis failed: {str(e)}"
        )


@router.get("/schedule/timeline")
async def schedule_timeline(project_id: str = Query(..., description="í”„ë¡œì íŠ¸ ID")):
    """
    Schedule íƒ€ì„ë¼ì¸ ì¡°íšŒ
    """
    try:
        result = await run_pipeline(
            kind="schedule_timeline", 
            payload={"project_id": project_id}
        )
        return {"status": "ok", "data": result}
    except Exception as e:
        logger.exception(f"[Schedule Timeline] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ===============================
# ì‹ ê·œ: í†µí•© Workflow
# ===============================

@router.post("/workflow/scope-schedule", response_model=WorkflowResponse)
async def workflow_scope_then_schedule(request: WorkflowRequest):
    """
    í†µí•© Workflow: Scope â†’ Schedule
    
    Example:
        {
          "project_id": "P001",
          "text": "RFP ë‚´ìš©...",
          "methodology": "agile",
          "calendar": {"start_date": "2025-02-01"},
          "sprint_length_weeks": 2
        }
    """
    try:
        # Payload êµ¬ì„±
        payload = {
            "project_id": request.project_id,
            "methodology": request.methodology or "waterfall",
            "calendar": request.calendar.model_dump() if request.calendar else {},
            "sprint_length_weeks": request.sprint_length_weeks or 2,
        }
        
        # Text or documents
        if request.text:
            payload["text"] = request.text
        elif request.documents:
            payload["documents"] = [doc.model_dump() for doc in request.documents]
        else:
            raise ValueError("Either 'text' or 'documents' must be provided")
        
        # Workflow ì‹¤í–‰
        result = await run_pipeline("workflow_scope_then_schedule", payload)
        
        if result.get("status") != "ok":
            raise ValueError(result.get("message", "Workflow failed"))
        
        # Scope ê²°ê³¼ íŒŒì‹±
        scope_result = result.get("scope", {})
        scope_response = ScopeResponse(
            status=scope_result.get("status", "ok"),
            message=scope_result.get("message"),
            project_id=request.project_id,
            requirements_json=scope_result.get("requirements_json"),
            srs_path=scope_result.get("srs_path"),
            rtm_csv=scope_result.get("rtm_csv"),
            charter_path=scope_result.get("charter_path"),
            business_plan_path=scope_result.get("business_plan_path"),
            requirements=scope_result.get("requirements", []),
            functions=scope_result.get("functions", []),
            deliverables=scope_result.get("deliverables", []),
            acceptance_criteria=scope_result.get("acceptance_criteria", []),
            rtm_json=scope_result.get("rtm_json"),
            pmp_outputs=scope_result.get("pmp_outputs"),
            stats=scope_result.get("stats")
        )
        
        # Schedule ê²°ê³¼ íŒŒì‹±
        schedule_result = result.get("schedule", {})
        
        # Critical path
        critical_path_data = schedule_result.get("_parsed_critical_path", [])
        
        # Timeline
        timeline_data = []
        if schedule_result.get("timeline") and isinstance(schedule_result["timeline"], str):
            try:
                timeline_path = Path(schedule_result["timeline"])
                if timeline_path.exists():
                    timeline_content = json.loads(timeline_path.read_text(encoding="utf-8"))
                    if isinstance(timeline_content, dict) and "tasks" in timeline_content:
                        timeline_data = timeline_content["tasks"]
            except Exception:
                pass
        
        schedule_response = ScheduleResponse(
            status=schedule_result.get("status", "ok"),
            message=schedule_result.get("message"),
            project_id=request.project_id,
            methodology=schedule_result.get("methodology", request.methodology),
            wbs_json_path=schedule_result.get("wbs_json_path"),
            plan_csv=schedule_result.get("plan_csv"),
            gantt_json=schedule_result.get("gantt_json"),
            timeline_path=schedule_result.get("timeline"),
            burndown_json=schedule_result.get("burndown_json"),
            critical_path=critical_path_data,
            timeline=timeline_data,
            pmp_outputs=schedule_result.get("pmp_outputs"),
            data=schedule_result.get("data"),
            change_requests=schedule_result.get("change_requests")
        )
        
        return WorkflowResponse(
            status=result.get("status", "ok"),
            message=result.get("message", "Workflow completed successfully"),
            project_id=request.project_id,
            scope=scope_response,
            schedule=schedule_response,
            summary=result.get("summary")
        )
        
    except ValueError as e:
        logger.error(f"[Workflow] Validation Error: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.exception(f"[Workflow] Error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Workflow execution failed: {str(e)}"
        )